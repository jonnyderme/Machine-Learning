{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7YzabwjTmk"
      },
      "source": [
        "## Εργασία 3 ##\n",
        "\n",
        "Καλωσήρθατε στην τρίτη σας εργασία. Η εργασία αυτή έχει σκοπό να σας βοηθήσει να εμπεδώσετε τα σύνολα μοντέλων.\n",
        "\n",
        "Στην εργασία αυτή θα πρέπει να συμπληρώσετε κώδικα Python 3 στα σημεία που αναφέρουν # YOUR CODE HERE. Μην τροποποιείτε τον κώδικα που βρίσκεται εκτός αυτών των περιοχών.\n",
        "\n",
        "Πρωτού παραδόσετε την εργασία σας σιγουρευτείτε ότι ο κώδικας σε όλα τα κελιά τρέχει σωστά. Για το σκοπό αυτό επιλέξτε από το μενού Χρόνος εκτέλεσης (runtime) -> Επανεκίνηση περιόδου λειτουργίας και εκτέλεση όλων.\n",
        "\n",
        "Συμπληρώστε το όνομα (NAME) και το AEM σας παρακάτω:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3-rBqXXbjyR0"
      },
      "outputs": [],
      "source": [
        "NAME = \"Δεϊρμεντζόγλου Ιωάννης\"\n",
        "AEM = \"10015\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egArYhcsTG-T"
      },
      "source": [
        "**1** Διαβάστε το διαθέσιμο από την sklearn σύνολο δεδομένων breast cancer, χωρίστε το σε δεδομένα εκπαίδευσης (X_train, y_train) και ελέγχου (X_test, y_test) σε ποσοστό 70%/30% αντίστοιχα με τη συνάρτηση train_test_split (τιμή για random_state βάλτε 0). Το σύνολο αφορά τη διάγνωση καρκίνου του μαστού με βάση μεταβλητές που υπολογίζονται από μια ψηφιοποιημένη εικόνα δείγματος μάζας μαστού που λήφθηκε μέσω αναρρόφησης λεπτής βελόνας (FNA). (2 μονάδες)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "id": "qgaPtNAmTCX7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29b99b6039fac516d5fa9c7649e40e1d",
          "grade": false,
          "grade_id": "cell-407a2dea48bfbf80",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 2: Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "# Step 3: Split the dataset into training and test sets with a 70%/30% split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "19LlgZx5cOLP",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e4b7add4e469cfc1221bdad01497d404",
          "grade": true,
          "grade_id": "cell-7387a72f2393ed9a",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"Τεστ ορθής ανάγνωσης και διαχωρισμού του συνόλου δεδομένων\"\"\"\n",
        "assert round(X_train[0][8], 5) == 0.1779\n",
        "assert round(X_test[0][8], 5) == 0.2116"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB8RexuPciQr"
      },
      "source": [
        "**2** Υλοποιήστε μια ντετερμινιστική εκδοχή της μεθόδου των τυχαίων υποχώρων, η οποία χτίζει τόσα μοντέλα όσες και οι μεταβλητές εισόδου, κάθε ένα από τα οποία αγνοεί και μία διαφορετική μεταβλητή εισόδου. Π.χ. το πρώτο μοντέλο αγνοεί την πρώτη, το δεύτερο αγνοεί τη δεύτερη κτλ. Χρησιμοποιήστε τη συνάρτηση clone από το sklearn.base για να δημιουργήστε αντίγραφο του βασικού μοντέλου σε κάθε επανάληψη. (4 μονάδες)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "id": "KuC_s04KcigR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5fbe3d9c3d8e46ffc9d9cf06a7644fa3",
          "grade": false,
          "grade_id": "cell-df57dc0d540a2518",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "class RandomSubspaceDet:\n",
        "    def __init__(self, estimator=DecisionTreeClassifier()):\n",
        "        self.base_estimator = estimator\n",
        "        self.models = []\n",
        "        self.ignore_indices = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.models = []\n",
        "        self.ignore_indices = []\n",
        "        n_features = X_train.shape[1]\n",
        "\n",
        "        for i in range(n_features):\n",
        "            # Clone the base estimator\n",
        "            model = clone(self.base_estimator)\n",
        "\n",
        "            # Indices of features to use (ignoring the i-th feature)\n",
        "            feature_indices = [j for j in range(n_features) if j != i]\n",
        "            self.ignore_indices.append(feature_indices)\n",
        "\n",
        "            # Train the model on the reduced feature set\n",
        "            model.fit(X_train[:, feature_indices], y_train)\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Collect predictions from all models\n",
        "        predictions = np.zeros((X.shape[0], len(self.models)))\n",
        "\n",
        "        for i, model in enumerate(self.models):\n",
        "            feature_indices = self.ignore_indices[i]\n",
        "            predictions[:, i] = model.predict(X[:, feature_indices])\n",
        "\n",
        "        # Aggregate the predictions (e.g., by majority voting)\n",
        "        y_pred = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=predictions)\n",
        "\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iDNUeGUEciwi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4db933425279be3712175509b4ba2f53",
          "grade": true,
          "grade_id": "cell-786f87fa5e67b624",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"Τεστ ορθής υλοποίησης RandomSubspaceDet\"\"\"\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rs = RandomSubspaceDet(estimator=DecisionTreeClassifier(random_state=1))\n",
        "rs.fit(X_train, y_train)\n",
        "assert round(accuracy_score(rs.predict(X_test), y_test), 4) == 0.9006"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n19eEYRNRnG-"
      },
      "source": [
        "**3** Υλοποιήστε τη μέθοδο AdaBoost όπως παρουσιάστηκε στο μάθημα. Χρησιμοποιήστε τη συνάρτηση clone από το sklearn.base για να δημιουργήστε αντίγραφο του βασικού μοντέλου σε κάθε επανάληψη. Χρησιμοποιήστε την παράμετρο sample_weight της fit του βασικού μοντέλου για να ορίσετε τα βάρη των παραδειγμάτων εκπαίδευσης. (4 μονάδες)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "id": "7NOoKPI8TBX6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7fe3d39eaf3d6a53e2b29f9ebd1e7b6a",
          "grade": false,
          "grade_id": "cell-946d2440bc05714e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "class AdaBoost:\n",
        "    def __init__(self, n_estimators=20, estimator=DecisionTreeClassifier(max_depth=1)):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.estimator = estimator\n",
        "        self.estimators = []\n",
        "        self.estimator_weights = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        m = len(X_train)\n",
        "        weights = np.ones(m) / m  # Initialize example weights\n",
        "\n",
        "        for t in range(self.n_estimators):\n",
        "            # Train model on the weighted training set\n",
        "            estimator = clone(self.estimator)\n",
        "            estimator.fit(X_train, y_train, sample_weight=weights)\n",
        "\n",
        "            y_pred = estimator.predict(X_train)\n",
        "            err = np.sum(weights * (y_pred != y_train)) / np.sum(weights)  # Weighted error\n",
        "\n",
        "            if err >= 0.5 or err == 0:\n",
        "                break\n",
        "\n",
        "            alpha = np.log((1 - err) / err)  # Weight of the current estimator\n",
        "            self.estimators.append(estimator)\n",
        "            self.estimator_weights.append(alpha)\n",
        "\n",
        "            # Update example weights\n",
        "            weights *= np.exp(alpha * (y_pred != y_train))\n",
        "            weights /= np.sum(weights)  # Normalization\n",
        "\n",
        "    def predict(self, X):\n",
        "        votes = np.zeros((len(X), len(np.unique(y_train))))  # Initialize votes\n",
        "\n",
        "        for estimator, alpha in zip(self.estimators, self.estimator_weights):\n",
        "            pred = estimator.predict(X)\n",
        "            for i, p in enumerate(pred):\n",
        "                votes[i, p] += alpha  # Weighted vote\n",
        "\n",
        "        return np.argmax(votes, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Suppress the FutureWarning about 'algorithm' deprecation\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    # Ίδιο αποτέλεσμα και με τη κλάση της sklearn\n",
        "    ab = AdaBoostClassifier(\n",
        "        n_estimators=20,\n",
        "        algorithm=\"SAMME\",  # Deprecated but used for reproducibility\n",
        "        estimator=DecisionTreeClassifier(max_depth=1, random_state=1)\n",
        "    )\n",
        "    ab.fit(X_train, y_train)\n",
        "\n",
        "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.9591\n"
      ],
      "metadata": {
        "id": "njo7xU9OBfNp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jVjqVcv_tmYk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32aff6a2c5ed06a7b34e982fc295d895",
          "grade": true,
          "grade_id": "cell-88a2903df26757f7",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"Τεστ ορθής υλοποίησης AdaBoost\"\"\"\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ab = AdaBoost(n_estimators=20, estimator=DecisionTreeClassifier(max_depth=1, random_state=1))\n",
        "ab.fit(X_train, y_train)\n",
        "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.9591"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0QkPMoBNz3T5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "71c5a522427b4fc254b65b5d431a767d",
          "grade": false,
          "grade_id": "cell-4f6f954c3531f480",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d4902f-209b-4be5-9c27-d8e93c44b1d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Ίδιο αποτέλεσμα και με τη κλάση της sklearn\n",
        "ab = AdaBoostClassifier(n_estimators=20, algorithm=\"SAMME\", estimator=DecisionTreeClassifier(max_depth=1, random_state=1))\n",
        "ab.fit(X_train, y_train)\n",
        "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.9591"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
